# Natural_Language_Processing
John Hopkins Data Science Capstone

## Purpose
The purpose is to work on understanding and building predictive text models, and include working on:

- Analyzing a large corpus of text documents
- Cleaning and analyzing text data
- Building and sampling from a predictive text model. 
- Building a predictive text product

## Project Tasks
- Understanding the problem
- Data acquisition and cleaning
- Exploratory analysis
- Statistical modeling
- Predictive modeling
- Creative exploration
- Creating a data product
- Creating a short slide deck pitching your product

## Dataset
Source data may be downloaded from following location:
https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip

The corpora are collected from publicly available sources via a web crawler. They have been parsed to remove duplicate entries, split into individual lines, and anonymised.

Each entry is tagged with the type of entry, based on the type of website it was collected from (e.g. newspaper or personal blog) Where possible, entries are tagged with subjects, based on title or keywords of original entry. Where it is not practical to tag entries, or no subject is found by the automated process, the entry is tagged with a '0'. The subjects and types are given as numerical codes.

Entries are also tagged with date of publication. If user comments are included, 
they are tagged with date of main entry.